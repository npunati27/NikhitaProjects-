{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pioneerfinal.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMD9RmDoJzjJ+xYtpd5mGqZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/npunati27/NikhitaProjects-/blob/pioneer/pioneerfinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCIFuWyKh1Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall tensorflow \n",
        "!pip install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euF5XXyCh6AA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get data link down below\n",
        "# https://drive.google.com/drive/folders/1TzwfNA5JRFTPO-kHMU___kILmOEodoBo?usp=sharing\n",
        "#change location in drive and mount drive to access the data \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRnkXkn8izdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define a dataloader\n",
        "import tensorflow as tf\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, csv_file='data/nyu2_train.csv', DEBUG=False):\n",
        "        self.shape_rgb = (480, 640, 3)\n",
        "        self.shape_depth = (240, 320, 1)\n",
        "        self.read_nyu_data(csv_file, DEBUG=DEBUG)\n",
        "\n",
        "    def nyu_resize(self, img, resolution=480, padding=6):\n",
        "        from skimage.transform import resize\n",
        "        return resize(img, (resolution, int(resolution*4/3)), preserve_range=True, mode='reflect', anti_aliasing=True )\n",
        "\n",
        "    def read_nyu_data(self, csv_file, DEBUG=False):\n",
        "        csv = open(csv_file, 'r').read()\n",
        "        nyu2_train = list((row.split(',') for row in (csv).split('\\n') if len(row) > 0))\n",
        "\n",
        "        # Dataset shuffling happens here\n",
        "        nyu2_train = shuffle(nyu2_train, random_state=0)\n",
        "\n",
        "        # Test on a smaller dataset\n",
        "        if DEBUG: nyu2_train = nyu2_train[:10]\n",
        "        \n",
        "        # A vector of RGB filenames.\n",
        "        self.filenames = [i[0] for i in nyu2_train]\n",
        "\n",
        "        # A vector of depth filenames.\n",
        "        self.labels = [i[1] for i in nyu2_train]\n",
        "\n",
        "        # Length of dataset\n",
        "        self.length = len(self.filenames)\n",
        "\n",
        "    def _parse_function(self, filename, label): \n",
        "        # Read images from disk\n",
        "        image_decoded = tf.image.decode_jpeg(tf.io.read_file(filename))\n",
        "        depth_resized = tf.image.resize(tf.image.decode_jpeg(tf.io.read_file(label)), [self.shape_depth[0], self.shape_depth[1]])\n",
        "\n",
        "        # Format\n",
        "        rgb = tf.image.convert_image_dtype(image_decoded, dtype=tf.float32)\n",
        "        depth = tf.image.convert_image_dtype(depth_resized / 255.0, dtype=tf.float32)\n",
        "        \n",
        "        # Normalize the depth values (in cm)\n",
        "        depth = 1000 / tf.clip_by_value(depth * 1000, 10, 1000)\n",
        "\n",
        "        return rgb, depth\n",
        "\n",
        "    def get_batched_dataset(self, batch_size):\n",
        "        self.dataset = tf.data.Dataset.from_tensor_slices((self.filenames, self.labels))\n",
        "        self.dataset = self.dataset.shuffle(buffer_size=len(self.filenames), reshuffle_each_iteration=True)\n",
        "        self.dataset = self.dataset.repeat()\n",
        "        self.dataset = self.dataset.map(map_func=self._parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "        self.dataset = self.dataset.batch(batch_size=batch_size)\n",
        "\n",
        "        return self.dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7pWlimsi7f3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define a loss function\n",
        "import tensorflow.keras.backend as K\n",
        "def depth_loss_function(y_true, y_pred, theta=0.1, maxDepthVal=1000.0/10.0):\n",
        "    \n",
        "    # Point-wise depth\n",
        "    l_depth = K.mean(K.abs(y_pred - y_true), axis=-1)\n",
        "\n",
        "    # Edges\n",
        "    dy_true, dx_true = tf.image.image_gradients(y_true)\n",
        "    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n",
        "    l_edges = K.mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)\n",
        "\n",
        "    # Structural similarity (SSIM) index\n",
        "    l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, maxDepthVal)) * 0.5, 0, 1)\n",
        "\n",
        "    # Weights\n",
        "    w1 = 1.0\n",
        "    w2 = 1.0\n",
        "    w3 = theta\n",
        "\n",
        "    return (w1 * l_ssim) + (w2 * K.mean(l_edges)) + (w3 * K.mean(l_depth))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwEAGPoui_xH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define a model\n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D, LeakyReLU, Concatenate\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "\n",
        "class UpscaleBlock(Model):\n",
        "    def __init__(self, filters, name):      \n",
        "        super(UpscaleBlock, self).__init__()\n",
        "        self.up = UpSampling2D(size=(2, 2), interpolation='bilinear', name=name+'_upsampling2d')\n",
        "        self.concat = Concatenate(name=name+'_concat') # Skip connection        \n",
        "        self.convA = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same', name=name+'_convA')\n",
        "        self.reluA = LeakyReLU(alpha=0.2)\n",
        "        self.convB = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same', name=name+'_convB')\n",
        "        self.reluB = LeakyReLU(alpha=0.2)\n",
        "    \n",
        "    def call(self, x):        \n",
        "        b = self.reluB( self.convB( self.reluA( self.convA( self.concat( [self.up(x[0]), x[1]] ) ) ) ) )\n",
        "        return b \n",
        "\n",
        "class Encoder(Model):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()                \n",
        "        self.base_model = DenseNet169(input_shape=(None, None, 3), include_top=False, weights='imagenet')   \n",
        "        print('Base model loaded {}'.format(DenseNet169.__name__))\n",
        "        \n",
        "        # Create encoder model that produce final features along with multiple intermediate features\n",
        "        outputs = [self.base_model.outputs[-1]]\n",
        "        for name in ['pool1', 'pool2_pool', 'pool3_pool', 'conv1/relu'] : outputs.append( self.base_model.get_layer(name).output )        \n",
        "        self.encoder = Model(inputs=self.base_model.inputs, outputs=outputs)\n",
        "        \n",
        "    def call(self, x):\n",
        "        return self.encoder(x)\n",
        "    \n",
        "class Decoder(Model):\n",
        "    def __init__(self, decode_filters):\n",
        "        super(Decoder, self).__init__()        \n",
        "        self.conv2 =  Conv2D(filters=decode_filters, kernel_size=1, padding='same', name='conv2')        \n",
        "        self.up1 = UpscaleBlock(filters=decode_filters//2,  name='up1')\n",
        "        self.up2 = UpscaleBlock(filters=decode_filters//4,  name='up2')\n",
        "        self.up3 = UpscaleBlock(filters=decode_filters//8,  name='up3')\n",
        "        self.up4 = UpscaleBlock(filters=decode_filters//16, name='up4')        \n",
        "        self.conv3 = Conv2D(filters=1, kernel_size=3, strides=1, padding='same', name='conv3')       \n",
        "\n",
        "    def call(self, features):        \n",
        "        x, pool1, pool2, pool3, conv1 = features[0], features[1], features[2], features[3], features[4]\n",
        "        up0 = self.conv2(x)        \n",
        "        up1 = self.up1([up0, pool3])        \n",
        "        up2 = self.up2([up1, pool2])        \n",
        "        up3 = self.up3([up2, pool1])        \n",
        "        up4 = self.up4([up3, conv1])        \n",
        "        return self.conv3( up4 )\n",
        "    \n",
        "class DepthEstimate(Model):\n",
        "    def __init__(self):\n",
        "        super(DepthEstimate, self).__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder( decode_filters = int(self.encoder.layers[-1].output[0].shape[-1] // 2 ) )\n",
        "        print('\\nModel created.')\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.decoder( self.encoder(x) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI1cwk5njF8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train the model\n",
        "batch_size     = 8\n",
        "learning_rate  = 0.0001\n",
        "epochs         = 10\n",
        "\n",
        "dl = DataLoader()\n",
        "train_generator = dl.get_batched_dataset(batch_size)\n",
        "\n",
        "print('Data loader ready.')\n",
        "\n",
        "optimizer = tensorflow.keras.optimizers.Adam(lr=learning_rate, amsgrad=True)\n",
        "model.compile(loss=depth_loss_function, optimizer=optimizer)\n",
        "\n",
        "import os\n",
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tensorflow.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)\n",
        "\n",
        "model.fit(train_generator, epochs=5, steps_per_epoch=dl.length//batch_size, callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxBWYq9NjUvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Load test data\n",
        "def load_test_data():    \n",
        "    print('Loading test data...', end='')\n",
        "    def extract_zip(input_zip):\n",
        "        input_zip=ZipFile(input_zip)\n",
        "        return {name: input_zip.read(name) for name in input_zip.namelist()}\n",
        "    data = extract_zip('/content/nyu_test.zip')\n",
        "    \n",
        "    rgb = np.load(BytesIO(data['eigen_test_rgb.npy']))\n",
        "    depth = np.load(BytesIO(data['eigen_test_depth.npy']))\n",
        "    crop = np.load(BytesIO(data['eigen_test_crop.npy']))\n",
        "    print('Test data loaded.\\n')\n",
        "    \n",
        "    return rgb, depth, crop\n",
        "\n",
        "def DepthNorm(x, maxDepth):\n",
        "    return maxDepth / x\n",
        "\n",
        "def predict(model, images, minDepth=10, maxDepth=1000, batch_size=2):\n",
        "    # Support multiple RGBs, one RGB image, even grayscale \n",
        "    if len(images.shape) < 3: images = np.stack((images,images,images), axis=2)\n",
        "    if len(images.shape) < 4: images = images.reshape((1, images.shape[0], images.shape[1], images.shape[2]))\n",
        "    # Compute predictions\n",
        "    predictions = model.predict(images, batch_size=batch_size)\n",
        "\n",
        "    #plot predictions \n",
        "    # Put in expected range\n",
        "    return np.clip(DepthNorm(predictions, maxDepth=1000), minDepth, maxDepth) / maxDepth\n",
        "\n",
        "def scale_up(scale, images):\n",
        "    from skimage.transform import resize\n",
        "    scaled = []\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        img = images[i]\n",
        "        output_shape = (scale * img.shape[0], scale * img.shape[1])\n",
        "        scaled.append( resize(img, output_shape, order=1, preserve_range=True, mode='reflect', anti_aliasing=True ) )\n",
        "\n",
        "    return np.stack(scaled)\n",
        "\n",
        "def evaluate(model, rgb, depth, crop, batch_size=6):\n",
        "    def compute_errors(gt, pred):\n",
        "        thresh = np.maximum((gt / pred), (pred / gt))\n",
        "        \n",
        "        a1 = (thresh < 1.25   ).mean()\n",
        "        a2 = (thresh < 1.25 ** 2).mean()\n",
        "        a3 = (thresh < 1.25 ** 3).mean()\n",
        "\n",
        "        abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
        "\n",
        "        rmse = (gt - pred) ** 2\n",
        "        rmse = np.sqrt(rmse.mean())\n",
        "\n",
        "        log_10 = (np.abs(np.log10(gt)-np.log10(pred))).mean()\n",
        "\n",
        "        return a1, a2, a3, abs_rel, rmse, log_10\n",
        "\n",
        "    depth_scores = np.zeros((6, len(rgb))) # six metrics\n",
        "\n",
        "    bs = batch_size\n",
        "\n",
        "    for i in range(len(rgb)//bs):    \n",
        "        x = rgb[(i)*bs:(i+1)*bs,:,:,:]\n",
        "        #plt.imshow(rgb[1])\n",
        "        # Compute results\n",
        "        true_y = depth[(i)*bs:(i+1)*bs,:,:]\n",
        "        pred_y = scale_up(2, predict(model, x/255, minDepth=10, maxDepth=1000, batch_size=bs)[:,:,:,0]) * 10.0\n",
        "\n",
        "        #imgplot = plt.imshow(rgb[1])\n",
        "        #imgplot_1 = plt.imshow(true_y[1])\n",
        "        #imgplot_2 = plt.imshow(pred_y[1])\n",
        "\n",
        "        # Test time augmentation: mirror image estimate\n",
        "        pred_y_flip = scale_up(2, predict(model, x[...,::-1,:]/255, minDepth=10, maxDepth=1000, batch_size=bs)[:,:,:,0]) * 10.0\n",
        "\n",
        "        # Crop based on Eigen et al. crop\n",
        "        true_y = true_y[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
        "        pred_y = pred_y[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
        "        pred_y_flip = pred_y_flip[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
        "        \n",
        "        # Compute errors per image in batch\n",
        "        for j in range(len(true_y)):\n",
        "            errors = compute_errors(true_y[j], (0.5 * pred_y[j]) + (0.5 * np.fliplr(pred_y_flip[j])))\n",
        "            \n",
        "            for k in range(len(errors)):\n",
        "                depth_scores[k][(i*bs)+j] = errors[k]\n",
        "\n",
        "    e = depth_scores.mean(axis=1)\n",
        "    w=10\n",
        "    h=10\n",
        "    fig=plt.figure(figsize=(8, 8))\n",
        "    columns = 4\n",
        "    rows = 5\n",
        "    for i in range(1, 5):\n",
        "      img = rgb[i]\n",
        "      fig.add_subplot(rows, columns, i)\n",
        "      plt.imshow(img)\n",
        "    plt.show()\n",
        "    for i in range(1, 5):\n",
        "      img = pred_y[i]\n",
        "      fig.add_subplot(rows, columns, i)\n",
        "      plt.imshow(img)\n",
        "    plt.show()\n",
        "    print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('a1', 'a2', 'a3', 'rel', 'rms', 'log_10'))\n",
        "    print(\"{:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}\".format(e[0],e[1],e[2],e[3],e[4],e[5]))\n",
        "    print('Evalution Completed')\n",
        "    return rgb, true_y, pred_y, xtesting data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwBWxYwwjo8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test on testing data\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_eager_execution(\n",
        "    config=None, device_policy=None, execution_mode=None\n",
        ")\n",
        "\n",
        "\n",
        "model = DepthEstimate()\n",
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "print('Model weights loaded.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVQrSepBj7cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print results\n",
        "rgb, depth, crop = load_test_data()\n",
        "rbg_n, true_n, pred_n, x = evaluate(model, rgb, depth, crop)\n",
        "\n",
        "#print \n",
        "w=10\n",
        "h=10\n",
        "fig=plt.figure(figsize=(80, 80))\n",
        "columns = 5\n",
        "rows = 5\n",
        "for i in range(1, 6):\n",
        "      img = pred_n[i]\n",
        "      fig.add_subplot(rows, columns, i)\n",
        "      plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "#print ground truth depth maps\n",
        "w=10\n",
        "h=10\n",
        "fig=plt.figure(figsize=(100, 100))\n",
        "columns = 5\n",
        "rows = 5\n",
        "for i in range(1, 6):\n",
        "      img = true_n[i]\n",
        "      fig.add_subplot(rows, columns, i)\n",
        "      plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "#print RGB images\n",
        "w=10\n",
        "h=10\n",
        "fig=plt.figure(figsize=(100, 100))\n",
        "columns = 5\n",
        "rows = 5\n",
        "for i in range(1, 6):\n",
        "      img = x[i]\n",
        "      fig.add_subplot(rows, columns, i)\n",
        "      plt.imshow(img)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}